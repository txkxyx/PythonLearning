第２章
・まとめ
パーセプトロンとは、「重み」「バイアス」というパラメーターを用いて、ある入力から決まって値を出力するアルゴリズム。
単層のパーセプトロンでは、出力を線形的にしか表現できないが、多層のパーセプトロンにすることで非線形的な判断を行うことができる。柔軟に

・話したいこと

・聞きたいこと
２層パーセプトロンは、U型の形となり２次方程式に似てい。層が深くなるにつれ、波の数が増えて出力の判断が変わるのか？

第３章
・まとめ
パーセプトロンは層を重ねるごとで、柔軟な判断を行うことができるがその分重みやバイアスを手動で決定しなければならない。そのパラメーターの設定を自動で行うのがニューラルネットワーク。

活性化関数 ー 重み付け記号の和の（入力信号の和）がどのうように発火するのかを決定する関数。入力の和aが閾値より高ければ発火するなどの決まりを決めている
    ステップ関数 ー 活性化関数の中での不等号によって発火を判断する関数。(0 or 1)
    シグモイド関数　ー ネイピア数を用いいた関数。ステップ関数とは異なり曲線的な値に変換される。(0.0 〜 1.0)
    ステップ関数とシグモイド関数では出力の滑らかさには違いがあるものの、重要な信号に対しては大きな出力を行う

出力層の関数　ー 隠れ層の最後の層の入力信号の和をもとに出力を決める関数
    恒等関数　ー 入力に対して加工を加えずそのまま出力する関数。分類問題に用いいられる
    ソフトマップ関数　ー （出力層のネイピア関数）/（入力層のネイピア関数の和）で表され、0から1までの数値が返される。

・聞きたいこと
ソフトマックス関数において、入力層と出力層のニューロンの数が異なる場合、関数の分母はどのように決定するのか

第４章
・まとめ
ニューラルネットワークのパラメーター設定を全て手作業で行うのは困難。損失関数を用いいることで、その関数の値が最小となるパラメーターを設定する。
訓練データを用いて、何回もパラメーターの更新を行う。
損失関数として用いられるのは２乗和誤差。ソフトマックス関数の出力と訓練データの正解ラベルとの誤差の２乗を全てたし、パラメーターに設定する。

損失関数を求め流のかというと、精度をパラメーター化することによりより細かい値のパラメーターの変動を見ることができるから